{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns   \n",
    "import matplotlib.pyplot as plt \n",
    "import xgboost as xgb \n",
    "import pickle \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, silhouette_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load and preprocess the data\n",
    "fly = pd.read_csv('C:/Users/abdul/OneDrive/Desktop/ByteWise_ML/Projects/Flight Delay Prediction/df_EDA.csv')\n",
    "fly.head(3)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "fly = fly.drop(['Month_Str', 'DayOfWeek_Str', 'ArrDelay', 'FlightDate', 'Unnamed: 0', 'Quarter','DayofMonth'], axis=1)\n",
    "\n",
    "# Define functions for handling categorical values\n",
    "def plane(value):\n",
    "    if value not in ['American Airlines', 'Delta Airlines', 'Southwest Airlines', 'United Airlines']:\n",
    "        return None\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def heli(value):\n",
    "    if value not in ['Chicago, IL', 'Atlanta, GA', 'New York, NY', 'Denver, CO', 'Dallas/Fort Worth, TX']:\n",
    "        return None\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def ship(value):\n",
    "    if value not in ['Chicago, IL', 'Atlanta, GA', 'New York, NY', 'Denver, CO', 'Dallas/Fort Worth, TX']:\n",
    "        return None\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Apply the functions to the relevant columns\n",
    "fly['Airlines'] = fly['Airlines'].apply(plane)\n",
    "fly['OriginCityName'] = fly['OriginCityName'].apply(heli)\n",
    "fly['DestCityName'] = fly['DestCityName'].apply(ship)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "fly = fly.dropna()\n",
    "\n",
    "# Define numeric columns\n",
    "def refine_dep_delay(value):\n",
    "    if value < 0:\n",
    "        return None \n",
    "    else:\n",
    "        return value\n",
    "\n",
    "fly['DepDelay'] = fly['DepDelay'].apply(refine_dep_delay)\n",
    "\n",
    "# Drop rows with NaN values again if any\n",
    "fly = fly.dropna()\n",
    "\n",
    "# Define features and target variable\n",
    "categorical_columns = ['Airlines', 'OriginCityName', 'DestCityName']\n",
    "numeric_columns = ['Month', 'DayOfWeek', 'DepDelay', 'AirTime', 'Distance']\n",
    "target_column = 'Flight_Status'\n",
    "\n",
    "X = fly[categorical_columns + numeric_columns]\n",
    "y = fly[target_column]\n",
    "\n",
    "# Create a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),  # Standardize numeric columns\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)  # One-hot encode categorical columns\n",
    "    ])\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with K-Fold Cross-Validation\n",
    "cv_results = cross_validate(xgb.XGBClassifier(eval_metric='logloss'), X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "# Train the XGBoost Classifier on the full training data\n",
    "model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f\"Cross-Validation Results:\")\n",
    "print(f\"Mean Training Accuracy: {cv_results['train_score'].mean():.3f}\")\n",
    "print(f\"Mean Validation Accuracy: {cv_results['test_score'].mean():.3f}\")\n",
    "\n",
    "# Clustering with K-Means\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "X_clustering = preprocessor.transform(X)  # Apply the same preprocessing to clustering data\n",
    "clusters = kmeans.fit_predict(X_clustering)\n",
    "\n",
    "# Add cluster labels to the original data for visualization\n",
    "fly['Cluster'] = clusters\n",
    "\n",
    "# Calculate Silhouette Score\n",
    "silhouette_avg = silhouette_score(X_clustering, clusters)\n",
    "print(f\"Silhouette Score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = fly[numeric_columns].corr()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=fly['Distance'], y=fly['AirTime'], hue=fly['Cluster'], palette='tab10', marker='o')\n",
    "plt.title('Clusters of Flights')\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('AirTime')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Save the model using pickle\n",
    "model_filename = 'Delay.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "with open('Pre-process.pkl', 'wb') as preprocessor_file:\n",
    "    pickle.dump(preprocessor, preprocessor_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
