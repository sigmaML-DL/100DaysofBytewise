{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/abdul/OneDrive/Desktop/ByteWise_ML/Project/yield_df.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove non-numeric rows from 'average_rain_fall_mm_per_year'\n",
    "def isstr(obj):\n",
    "    try:\n",
    "        float(obj)\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "to_drop = df[df['average_rain_fall_mm_per_year'].apply(isstr)].index\n",
    "df = df.drop(to_drop)\n",
    "\n",
    "# Summing 'hg/ha_yield' per country and crop\n",
    "country = df['Area'].unique()\n",
    "yield_per_country = [df[df['Area'] == state]['hg/ha_yield'].sum() for state in country]\n",
    "\n",
    "crops = df['Item'].unique()\n",
    "yield_per_item = [df[df['Item'] == crop]['hg/ha_yield'].sum() for crop in crops]\n",
    "\n",
    "# Select columns for modeling\n",
    "col = ['Year', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp', 'Area', 'Item', 'hg/ha_yield']\n",
    "df = df[col]\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop('hg/ha_yield', axis=1)\n",
    "y = df['hg/ha_yield']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: OneHotEncoding (with sparse=False) and Standardization\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('oneHotEncoder', ohe, [4, 5]),  # Encode 'Area' and 'Item'\n",
    "        ('standardization', scaler, [0, 1, 2, 3])  # Standardize numerical features\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert to dense arrays before reshaping\n",
    "X_train_preprocessed = np.array(X_train_preprocessed)\n",
    "X_test_preprocessed = np.array(X_test_preprocessed)\n",
    "\n",
    "# CNN-LSTM model\n",
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Conv1D(64, 2, activation='relu', input_shape=(X_train_preprocessed.shape[1], 1)))\n",
    "cnn_lstm_model.add(MaxPooling1D(2))\n",
    "cnn_lstm_model.add(LSTM(50, return_sequences=True))\n",
    "cnn_lstm_model.add(LSTM(50))\n",
    "cnn_lstm_model.add(Dropout(0.3))\n",
    "cnn_lstm_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "cnn_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape input for CNN-LSTM\n",
    "X_train_preprocessed_reshaped = np.reshape(X_train_preprocessed, (X_train_preprocessed.shape[0], X_train_preprocessed.shape[1], 1))\n",
    "X_test_preprocessed_reshaped = np.reshape(X_test_preprocessed, (X_test_preprocessed.shape[0], X_test_preprocessed.shape[1], 1))\n",
    "\n",
    "# Train the CNN-LSTM model with 5 epochs\n",
    "cnn_lstm_model.fit(X_train_preprocessed_reshaped, y_train, epochs=5, batch_size=16, validation_data=(X_test_preprocessed_reshaped, y_test))\n",
    "\n",
    "# RNN model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(100, activation='relu', input_shape=(X_train_preprocessed.shape[1], 1)))\n",
    "rnn_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the RNN model with 5 epochs\n",
    "rnn_model.fit(X_train_preprocessed_reshaped, y_train, epochs=5, batch_size=16, validation_data=(X_test_preprocessed_reshaped, y_test))\n",
    "\n",
    "# Decision Tree Regressor model\n",
    "dtr_model = DecisionTreeRegressor()\n",
    "dtr_model.fit(X_train_preprocessed, y_train)\n",
    "y_pred_dtr = dtr_model.predict(X_test_preprocessed)\n",
    "dtr_mse = mean_squared_error(y_test, y_pred_dtr)\n",
    "\n",
    "def prediction(Year, average_rain_fall_mm_per_year, pesticides_tonnes, avg_temp, Area, Item):\n",
    "    # Create a feature array with the input values\n",
    "    features = np.array([[Year, average_rain_fall_mm_per_year, pesticides_tonnes, avg_temp, Area, Item]])\n",
    "    \n",
    "    # Apply the preprocessing pipeline to the features (OneHotEncoding + Standardization)\n",
    "    transformed_feature = preprocessor.transform(features)\n",
    "    \n",
    "    # Use the preprocessed features to predict using the trained Decision Tree Regressor\n",
    "    predicted = dtr_model.predict(transformed_feature).reshape(1, -1)\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "# Example input values for the prediction\n",
    "Year = 2000\n",
    "average_rain_fall_mm_per_year = 59.0\n",
    "pesticides_tonnes = 3024.11\n",
    "avg_temp = 26.55\n",
    "Area = \"Saudi Arabia\"\n",
    "Item = \"Sorghum\"\n",
    "\n",
    "# Call the prediction function\n",
    "result = prediction(Year, average_rain_fall_mm_per_year, pesticides_tonnes, avg_temp, Area, Item)\n",
    "print(\"Predicted Yield:\", result)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "cnn_lstm_loss, cnn_lstm_accuracy = cnn_lstm_model.evaluate(X_test_preprocessed_reshaped, y_test, verbose=0)\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test_preprocessed_reshaped, y_test, verbose=0)\n",
    "\n",
    "print(f'CNN-LSTM Accuracy: {cnn_lstm_accuracy}, Loss: {cnn_lstm_loss}')\n",
    "print(f'RNN Accuracy: {rnn_accuracy}, Loss: {rnn_loss}')\n",
    "print(f'Decision Tree Regressor Mean Squared Error: {dtr_mse}')\n",
    "\n",
    "# Save models using pickle\n",
    "with open('cnn_lstm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(cnn_lstm_model, file)\n",
    "\n",
    "with open('rnn_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rnn_model, file)\n",
    "\n",
    "with open('dtr_model.pkl', 'wb') as file:\n",
    "    pickle.dump(dtr_model, file)\n",
    "\n",
    "# Save the preprocessor using pickle\n",
    "with open('preprocessor.pkl', 'wb') as file:\n",
    "    pickle.dump(preprocessor, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
